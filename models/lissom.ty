"""
Example of a LISSOM-based position, orientation, phase, direction,
speed, ocular dominance, disparity, spatial frequency, and color
preference map.

Orientation, direction, ocular dominance, disparity, spatial frequency
and color dimensions can be turned on and off; see the dims parameter
below.  All maps inherently include position information, speed is
always present when direction is included, and phase is always present
when orientation is included.  The training dataset (e.g. natural
images or artificial inputs) can be selected using the dataset
parameter below.

For example,

  ./topographica -p "dims=['or','od']" -p "dataset='Gaussian'" examples/lissom.ty

selects a Gaussian OR/OD simulation.  Gaussian OR/OD/DR/DY is the default.

These simulations are intended to be close (but approximate) matches
to the various map simulations in chapter 5 of Miikkulainen, Bednar,
Choe, and Sirosh (2005), Computational Maps in the Visual Cortex,
Springer.  Specifically:

    dataset='Gaussian', dims=['or']:           CVMC Figure 5.9
    dataset='Nature',   dims=['or']:           CVMC Figure 5.13 Nature
    dataset='Gaussian', dims=['od','dr']:      CVMC Figure 5.23
    dataset='Gaussian', dims=['or','od']:      CVMC Figure 5.27
    dataset='Gaussian', dims=['or','od','dr']: CVMC Figure 5.29
    dataset='Nature',   dims=['or','od','dr']: CVMC Figure 5.31

Known differences include:

 - The cortex_density is smaller for practicality (142 in the book).
 - The matching is not yet perfect at different densities
 - The lateral inhibitory radius is up to 0.5 matrix units greater
   than in the book, because Topographica enforces good
   circular-shaped CF outlines.
 - Input patterns are evaluated on the entire retina, instead of only up
   to bounds_multiplier=2.5 times the gaussian sigma in the book
 - Initial weight patterns are not smoothed around the edges, unlike
   smooth_circular_outlines=True and smooth_circular_radius_trim=-0.25
   used in the book
 - Initial weight patterns are all random within a gaussian envelope
   rather than random afferent and Gaussian sigma preset_sigma_exc=11.076
   preset_sigma_inh=71.76 lateral weights used in the book.
 - Inhibitory weight pruning is disabled (not pruning all weights below
   1e-5 as in the book)

There may be other small differences, as this file has not yet been
compared exhaustively to the original simulations.

Furthermore, some combinations of dimensions can approximately replicate
various map simulations in:

 - Tikesh Ramtohul. A self-organizing model of disparity maps in the
   primary visual cortex. Master's thesis, The University of
   Edinburgh, Scotland, UK, 2006.
 - James A. Bednar, Judah B. De Paula, and Risto Miikkulainen.
   Self-organization of color opponent receptive fields and laterally
   connected orientation maps. Neurocomputing, 65-66:69-76, 2005.
 - Judah Ben De Paula. Modeling the Self-Organization of Color
   Selectivity in the Visual Cortex.  PhD thesis, Department of
   Computer Sciences, The University of Texas at Austin, Austin, TX,
   2007.
 - Christopher M. Palmer and James A. Bednar. Topographic and laminar
   organization of spatial frequency and orientation in a
   developmental model of V1 using natural images. In Society for
   Neuroscience Abstracts, Society for Neuroscience, www.sfn.org,
   2007. Program No. 395.13.

Specifically:
    dataset='Gaussian',    dims=['or','dy']:           ramtohul:msc06
    dataset='FoliageA',    dims=['or','rg']:           jbednar:neurocomputing05
    dataset='FoliageB',    dims=['or','cr']:           depaula:phd07
    dataset='Nature',      dims=['or','sf']:           palmer:sfn07
"""
__version__='$Revision: 8706 $'


from math import pi, sqrt
import copy

import numpy
import param

from topo.misc.util import linearly_interpolate

from topo import learningfn,numbergen,transferfn,pattern,projection,responsefn,sheet

import topo.learningfn.optimized
import topo.learningfn.projfn
import topo.transferfn.optimized
import topo.pattern.random
import topo.pattern.image
import topo.responsefn.optimized
import topo.sheet.lissom
import topo.sheet.optimized


### Specify weight initialization, response function, and learning function
projection.CFProjection.cf_shape=pattern.Disk(smoothing=0.0)
projection.CFProjection.weights_generator=pattern.Constant()
projection.CFProjection.response_fn=responsefn.optimized.CFPRF_DotProduct_opt()
projection.CFProjection.learning_fn=learningfn.optimized.CFPLF_Hebbian_opt()
projection.CFProjection.weights_output_fns=[transferfn.optimized.CFPOF_DivisiveNormalizeL1_opt()]
projection.SharedWeightCFProjection.response_fn=responsefn.optimized.CFPRF_DotProduct_opt()

### Default for tutorial
pattern.Line.scale=0.9
pattern.Gaussian.size=0.08333
pattern.Gaussian.aspect_ratio=4.0

numpy.random.seed((500,500))

# base seed for input patterns; change to get completely new random
# input pattern parameters
input_seed = 500


# CB: not sure this is the clearest way to do it...
# (also need to rename 'colormap').
natural_image_sets = ['Nature','FoliageA','FoliageB']
# Could we avoid some of the various ifs in this file by using
# dictionaries?
# I haven't yet used this file enough to know what's best...


# Parameters that can be passed on the command line using -p
from topo.misc.commandline import global_params as p
p.add(

    dataset=param.ObjectSelector(default='Gaussian',objects=
        ['Gaussian','Nature','FoliageA','FoliageB'],doc="""
        Set of input patterns to use::

          :'Gaussian': Two-dimensional Gaussians
          :'Nature':   Shouval's 1999 monochrome 256x256 images
          :'FoliageA': McGill calibrated LMS foliage/ image subset (5)
          :'FoliageB': McGill calibrated LMS foliage/ image subset (25)"""),

    dims=param.List(default=['or','od','dr','dy'],class_=str,doc="""
        Stimulus dimensions to include, out of the possible list::

          :'or': Orientation
          :'od': Ocular dominance
          :'dr': Direction of motion
          :'dy': Disparity
          :'rg': Red/Green color (not to be combined with cr)
          :'cr': RGB/LMS Color (not to be combined with rg)
          :'sf': Spatial frequency

        Each additional dimension increases the realism, but adds
        significant complexity, computation time, and memory
        requirements.  If an empty list is supplied, all
        available dimensions are used."""),

    retina_density=param.Number(default=24.0,bounds=(0,None),
        inclusive_bounds=(False,True),doc="""
        The nominal_density to use for the retina."""),

    lgn_density=param.Number(default=24.0,bounds=(0,None),
        inclusive_bounds=(False,True),doc="""
        The nominal_density to use for the LGN."""),

    cortex_density=param.Number(default=48.0,bounds=(0,None),
        inclusive_bounds=(False,True),doc="""
        The nominal_density to use for V1."""),

    max_disparity=param.Number(default=4.0,bounds=(0,None),doc="""
        Maximum disparity between input pattern positions in left and
        right eyes."""),

    speed=param.Number(default=0.0,bounds=(0,None),doc="""
        Distance in sheet coordinates between successive frames, when
        translating patterns."""),

    expand_sf_test_range=param.Boolean(default=False,doc="""
        By default, measure_sine_pref() measures SF at the sizes of RF
        used, for speed, but if expand_sf_test_range is True, will
        also test over a larger range, including half the size of the
        smallest and twice the size of the largest."""))


# Convenient shortcut:
if p.dims==[]:
    p.dims=['or','od','dr','dy','cr','sf']

if p.dataset in natural_image_sets or 'dy' in p.dims:
    p.set_default('retina_density',48.0)


### Set up parameters for specified type of simulation
# Defaults:                         # parameters for:
center_polarities=['On','Off']      # oo
rg_cone_types=['']                  # rg
cone_types=['']                     # rg,cr
opponent_types=['']                 # rg
basic_opponent_types=['']           # rg
eyes=['']                           # od,dy
lags=['']                           # dr
speed=0.0                           # dr
disparity_bound = 0.0               # dy
position_bound = 0.75               # dy
sf_channels = 1                     # sf
sf_spacing = 2.0                    # sf
v1aff_radius=0.27083                # sf
lgnaff_radius=0.375                 # sf


topo.sim.name = "lissom_oo_" + '_'.join(p.dims)
if 'od' in p.dims or 'dy' in p.dims:
    eyes=['Left','Right']

if 'dr' in p.dims:
    lags=['0','1','2','3']
    if p.speed == 0:
        speed=2.0/24.0 # Useful speeds range from 0.0 - 3.0/24.0.
    else:
        speed=p.speed

if 'dy' in p.dims:
    disparity_bound = p.max_disparity*0.041665/2.0
    if p.max_disparity > 0.0: position_bound = 0.70833

if 'rg' in p.dims:
    rg_cone_types=['Red','Green']
    cone_types=['Red','Green']
    opponent_types=['Red-Green ','Green-Red ','Luminosity ']
    basic_opponent_types=['Red-Green ','Green-Red ']

if 'cr' in p.dims:
    rg_cone_types=['Red','Green']
    cone_types=['Red','Green','Blue']
    opponent_types=['Red-Green ','Green-Red ','Blue-RedGreen ','Luminosity ']
    basic_opponent_types=['Red-Green ','Green-Red ']
    p.dims.append('rg')

if 'sf' in p.dims:
    sf_channels=2 # Useful values are 2,3,4.

# Should rewrite the code below in terms of these lists for
# consistency and to allow arbitrary lists of sizes.
sf_channel_nums=range(1,sf_channels+1)
sf_relative_sizes=[sf_spacing**(channel-1) for channel in sf_channel_nums]


### Input patterns and LGN sheets
num_inputs=1

if p.dataset=="Gaussian":
    input_type=pattern.Gaussian
    ids=1.0
elif p.dataset in natural_image_sets:
    input_type=pattern.image.FileImage
    ids=4.0


# helper fns for synthesizing a specified hue

# CEBALERT: generating r,g,b from h,1,v means one of r,g,b will always
# be 0 (s should also be varied).
# CB: the import must be in the function to support pickling. A hack,
# but these functions will be removed sometime anyway.
def h_to_r(h):
    from colorsys import hsv_to_rgb
    return hsv_to_rgb(h,1.0,1.0)[0]
def h_to_g(h):
    from colorsys import hsv_to_rgb
    return hsv_to_rgb(h,1.0,1.0)[1]
def h_to_b(h):
    from colorsys import hsv_to_rgb
    return hsv_to_rgb(h,1.0,1.0)[2]


for e in eyes:
    for n in lags:
        for cone in cone_types:

            if p.dataset=="Gaussian":
                r=0 if 'rg' not in p.dims else numbergen.UnaryOperator(
                    numbergen.UniformRandom(lbound=0,ubound=1,seed=78),h_to_r)
                g=0 if 'rg' not in p.dims else numbergen.UnaryOperator(
                    numbergen.UniformRandom(lbound=0,ubound=1,seed=78),h_to_g)
                b=0 if 'cr' not in p.dims else numbergen.UnaryOperator(
                    numbergen.UniformRandom(lbound=0,ubound=1,seed=78),h_to_b)

                # 6n distinct random seeds (for n inputs, each of which has 6 random streams)
                inputs=[input_type(
                    x=numbergen.UniformRandom(lbound=-position_bound,ubound=position_bound,seed=input_seed+6*i) + \
                      numbergen.UniformRandom(lbound=-disparity_bound,ubound=disparity_bound,seed=input_seed+1+6*i)*(-1)**(e=='Left'),
                    y=numbergen.UniformRandom(lbound=-0.75,ubound=0.75,seed=input_seed+2+6*i),
                    orientation=0 if n != '' else numbergen.UniformRandom(lbound=-pi,ubound=pi,seed=input_seed+3+6*i),
                    size=0.088388*(3**('or' not in p.dims)) * \
                      numbergen.UniformRandom(lbound=1,ubound=sf_spacing**(sf_channels-1),
                                              seed=input_seed+4+6*i)**('sf' in p.dims),
                    aspect_ratio=4.66667 if 'or' in p.dims else 1.0,
                    scale=1.0 if 'od' not in p.dims else \
                     (2.0-2*(r*(cone=='Red')+g*(cone=='Green')+b*(cone=='Blue')) - \
                      numbergen.UniformRandom(lbound=0,ubound=2,seed=input_seed+5+6*i)*('rg' not in p.dims) \
                      if e=='Right' else \
                      2*(r*(cone=='Red')+g*(cone=='Green')+b*(cone=='Blue')) + \
                      numbergen.UniformRandom(lbound=0,ubound=2,seed=input_seed+5+6*i)*('rg' not in p.dims)))
                for i in xrange(num_inputs)]
                input_composite=pattern.SeparatedComposite(min_separation=2.2*v1aff_radius,generators=inputs)

            elif p.dataset in natural_image_sets:
                scalingfactor=[1.4*0.9,1.4,1.4*0.97] if 'cr' in p.dims else [1.0,1.0,1.0]
                if p.dataset=="FoliageA":
                    image_filenames=["images/mcgill/foliage_a/%02d_%d.png"%(i,cone_types.index(cone))
                                     for i in xrange(5)]
                elif p.dataset=="FoliageB":
                    image_filenames=["images/mcgill/foliage_b/%02d_%d.png"%(i,cone_types.index(cone))
                                     for i in xrange(1,26)]
                elif p.dataset=="Nature":
                    image_filenames=["images/shouval/combined%02d.png"%(i+1) for i in xrange(25)]

                # CEBALERT: (for all input types) In the case of OD
                # and CR, 'left eye' RGB is (x,y,z) but 'right eye'
                # RGB is (2-x,2-y,2-z), i.e. a different hue.  (Not a
                # problem in RGB retina model.)

                # 5n distinct random seeds (for n images, each of which has 5 random streams)
                inputs=[input_type(
                    filename=f, size=10.0, cache_image=False,
                    x=numbergen.UniformRandom(lbound=-0.75,ubound=0.75,seed=input_seed+5*i) + \
                    numbergen.UniformRandom(lbound=-disparity_bound,ubound=disparity_bound,
                                            seed=input_seed+1+5*i)*(-1)**(e=='Left'),
                    y=numbergen.UniformRandom(lbound=-0.75,ubound=0.75,seed=input_seed+2+5*i),
                    orientation=0 if n != '' else numbergen.UniformRandom(lbound=-pi,ubound=pi,seed=input_seed+3+5*i),
                    scale=scalingfactor[cone_types.index(cone)]* \
                            1.0 if 'od' not in p.dims else \
                            (2.0-numbergen.UniformRandom(lbound=0,ubound=2,seed=input_seed+4+5*i)) if e=='Right' else \
                            numbergen.UniformRandom(lbound=0,ubound=2,seed=input_seed+4+5*i))
                for f,i in zip(image_filenames,range(len(image_filenames)))]
                input_composite=pattern.Selector(generators=inputs)


            if n != '':
                input_moved=pattern.Sweeper(
                    generator=copy.deepcopy(input_composite),
                    step=int(n),speed=speed,
                    orientation=numbergen.UniformRandom(lbound=-pi,ubound=pi,seed=input_seed-1))
            else: input_moved=input_composite

            topo.sim[e+cone+'Retina'+n]=sheet.GeneratorSheet(
                nominal_density=p.retina_density,
                input_generator=input_moved,
                period=1.0, phase=0.05,
                nominal_bounds=sheet.BoundingBox(radius=0.5+v1aff_radius*sf_spacing**(sf_channels-1) + \
                                                 lgnaff_radius*sf_spacing**(sf_channels-1)))
        for l in center_polarities:
            for opponent in opponent_types:
                topo.sim[e+opponent+'LGN'+l+n]=sheet.CFSheet(
                    nominal_density=p.lgn_density,
                    nominal_bounds=sheet.BoundingBox(radius=0.5+v1aff_radius),
                    output_fns=[transferfn.PiecewiseLinear(lower_bound=0.0,upper_bound=1.0)],
                    measure_maps=False)
            for channel in xrange(2,sf_channels+1):
                topo.sim[e+'LGN'+l+n+'SF'+str(channel)]=sheet.CFSheet(
                    nominal_density=p.lgn_density,
                    nominal_bounds=sheet.BoundingBox(radius=0.5+v1aff_radius*sf_spacing**(channel-1)),
                    output_fns=[transferfn.PiecewiseLinear(lower_bound=0.0,upper_bound=1.0)],
                    measure_maps=False)


topo.sim['V1'] = sheet.lissom.LISSOM(nominal_density=p.cortex_density,
                                     tsettle=9,nominal_bounds=sheet.BoundingBox(radius=0.5))

topo.sim['V1'].output_fns[0].lower_bound=0.076 if p.dataset in natural_image_sets else 0.083
topo.sim['V1'].output_fns[0].upper_bound=0.626 if p.dataset in natural_image_sets else 0.633

# DoG weights for the LGN
centerg   = pattern.Gaussian(size=0.07385,aspect_ratio=1.0,
                             output_fns=[transferfn.DivisiveNormalizeL1()])
surroundg = pattern.Gaussian(size=0.29540,aspect_ratio=1.0,
                             output_fns=[transferfn.DivisiveNormalizeL1()])

# Scale the strength of the afferent connections, depending on how much patterns overlap
strength=[2.33, 2.38, 2.53, 2.8] # For speed=0,1/24.0,2/24.0,3/24.0; from CMVC
if p.dataset in natural_image_sets:
    strength=[4.7, 4.8, 5.1, 5.8]

strength_scale=linearly_interpolate(strength,speed*24.0)


# Convenience variable: number of afferent connections to V1
num_aff=len(center_polarities)*len(eyes)*len(lags)*len(opponent_types)

for e in eyes:
    for n in lags:
        for l in center_polarities:
            basic_opponent_types_tmp=list(basic_opponent_types)
            basic_opponent_types_tmp.reverse()
            for (cone,opponentcenter,opponentsurround) in zip(rg_cone_types,basic_opponent_types,basic_opponent_types_tmp):
                topo.sim.connect(
                    e+cone+'Retina'+n, e+opponentcenter+'LGN'+l+n, name='AfferentCenter',
                    connection_type=projection.SharedWeightCFProjection, delay=0.05,
                    strength=strength_scale*(-1)**center_polarities.index(l),
                    nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                    weights_generator=centerg)

                topo.sim.connect(
                    e+cone+'Retina'+n, e+opponentsurround+'LGN'+l+n, name='AfferentSurround',
                    connection_type=projection.SharedWeightCFProjection, delay=0.05,
                    strength=strength_scale*(-1)**(1+center_polarities.index(l)),
                    nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                    weights_generator=surroundg)

                if 'sf' in p.dims and 'rg' not in p.dims:
                    for channel in xrange(2,sf_channels+1):
                        topo.sim.connect(
                            e+cone+'Retina'+n, e+opponentcenter+'LGN'+l+n+'SF'+str(channel),
                            name='AfferentCenter'+str(channel),
                            delay=0.05,connection_type=projection.SharedWeightCFProjection,
                            strength=strength_scale*(-1)**center_polarities.index(l),
                            nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius*sf_spacing**(channel-1)),

                            weights_generator=pattern.Gaussian(size=0.07385*sf_spacing**(channel-1),aspect_ratio=1.0,
                                                               output_fns=[transferfn.DivisiveNormalizeL1()]))

                        topo.sim.connect(
                            e+cone+'Retina'+n, e+opponentsurround+'LGN'+l+n+'SF'+str(channel),
                            name='AfferentSurround'+str(channel),
                            delay=0.05,connection_type=projection.SharedWeightCFProjection,
                            strength=strength_scale*(-1)**(1+center_polarities.index(l)),
                            nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius*sf_spacing**(channel-1)),

                            weights_generator=pattern.Gaussian(size=0.29540*sf_spacing**(channel-1),aspect_ratio=1.0,
                                                               output_fns=[transferfn.DivisiveNormalizeL1()]))

                if 'cr' in p.dims:
                    topo.sim.connect(
                        e+cone+'Retina'+n, e+'Blue-RedGreen'+' LGN'+l+n,
                        name='AfferentCenter'+cone,
                        delay=0.05,connection_type=projection.SharedWeightCFProjection,
                        strength=4.7*(-1)**(1+center_polarities.index(l))/2,
                        nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                        weights_generator=centerg)

            if 'cr' in p.dims:
                topo.sim.connect(
                    e+'Blue'+'Retina'+n, e+'Blue-RedGreen'+' LGN'+l+n,
                    name='AfferentCenter'+'Blue',
                    delay=0.05,connection_type=projection.SharedWeightCFProjection,
                    strength=4.7*(-1)**center_polarities.index(l),
                    nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                    weights_generator=centerg)

            for cone in cone_types:
                if 'Luminosity ' in opponent_types:
                    topo.sim.connect(
                        e+cone+'Retina'+n, e+'Luminosity LGN'+l+n,
                        name='AfferentCenter'+cone,
                        delay=0.05,connection_type=projection.SharedWeightCFProjection,
                        strength=strength_scale*(-1)**center_polarities.index(l)/len(cone_types),
                        nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                        weights_generator=centerg)

                    topo.sim.connect(
                        e+cone+'Retina'+n, e+'Luminosity LGN'+l+n,
                        name='AfferentSurround'+cone,
                        delay=0.05,connection_type=projection.SharedWeightCFProjection,
                        strength=strength_scale*(-1)**(1+center_polarities.index(l))/len(cone_types),
                        nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius),
                        weights_generator=surroundg)

                    for channel in xrange(2,sf_channels+1):
                        topo.sim.connect(
                            e+cone+'Retina'+n, e+'LGN'+l+n+'SF'+str(channel),
                            name='AfferentCenter'+cone+str(channel),
                            delay=0.05,connection_type=projection.SharedWeightCFProjection,
                            strength=strength_scale*(-1)**center_polarities.index(l)/len(cone_types),
                            nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius*sf_spacing**(channel-1)),

                            weights_generator=pattern.Gaussian(size=0.07385*sf_spacing**(channel-1),aspect_ratio=1.0,
                                                               output_fns=[transferfn.DivisiveNormalizeL1()]))

                        topo.sim.connect(
                            e+cone+'Retina'+n, e+'LGN'+l+n+'SF'+str(channel),
                            name='AfferentSurround'+cone+str(channel),
                            delay=0.05,connection_type=projection.SharedWeightCFProjection,
                            strength=strength_scale*(-1)**(1+center_polarities.index(l))/len(cone_types),
                            nominal_bounds_template=sheet.BoundingBox(radius=lgnaff_radius*sf_spacing**(channel-1)),

                            weights_generator=pattern.Gaussian(size=0.29540*sf_spacing**(channel-1),aspect_ratio=1.0,
                                                               output_fns=[transferfn.DivisiveNormalizeL1()]))


            for opponent in opponent_types:
                topo.sim.connect(
                    e+opponent+'LGN'+l+n,'V1',delay=0.05,
                    dest_port=('Activity','JointNormalize', 'Afferent'),
                    strength=1.0,name=e+opponent+'LGN'+l+'Afferent'+n,
                    connection_type=projection.CFProjection,
                    weights_generator=pattern.random.GaussianCloud(gaussian_size=2*v1aff_radius),
                    nominal_bounds_template=sheet.BoundingBox(radius=v1aff_radius),
                    learning_rate=0.9590/num_aff/ids)

            for channel in xrange(2,sf_channels+1):
                topo.sim.connect(
                    e+'LGN'+l+n+'SF'+str(channel),'V1',delay=0.05,
                    dest_port=('Activity','JointNormalize', 'Afferent'),
                    strength=1.0,name=e+'LGN'+l+'Afferent'+n+'SF'+str(channel),
                    connection_type=projection.CFProjection,
                    weights_generator=pattern.random.GaussianCloud(gaussian_size=2*v1aff_radius*sf_spacing**(channel-1)),
                    nominal_bounds_template=sheet.BoundingBox(radius=v1aff_radius*sf_spacing**(channel-1)),
                    learning_rate=0.9590/num_aff/ids)


topo.sim.connect('V1','V1',delay=0.05,name='LateralExcitatory',
                 connection_type=projection.ResizableCFProjection,
                 strength=1.2 if p.dataset in natural_image_sets else 0.9,
                 weights_generator=pattern.random.GaussianCloud(gaussian_size=2*0.10417),
                 nominal_bounds_template=sheet.BoundingBox(radius=0.10417),
                 learning_rate=2.55528/ids)

topo.sim.connect('V1','V1',delay=0.05,name='LateralInhibitory',
                 connection_type=projection.CFProjection,
                 strength=-1.75 if p.dataset in natural_image_sets else -0.9,
                 weights_generator=pattern.random.GaussianCloud(gaussian_size=2*0.22917),
                 nominal_bounds_template=sheet.BoundingBox(radius=0.22917),
                 learning_rate=1.80873/ids/5 if p.dataset in natural_image_sets else 1.80873/ids)


### Actions scheduled to occur as the simulation proceeds.
st=(1.0/2.0 if p.dataset in natural_image_sets else 1.0/num_inputs)
sheet.lissom.schedule_events("topo.sim['V1']",st=st,
                             aff_name="Afferent",ids=ids,
                             increase_inhibition=(p.dataset in natural_image_sets))

# These simulations are slow, so we want more progress reports
topo.sim.schedule_command(25*st,'pass')
topo.sim.schedule_command(50*st,'pass')
topo.sim.schedule_command(100*st,'pass')
topo.sim.schedule_command(150*st,'pass')


### Default locations for model editor
vs=[None]*(1+len(center_polarities))*len(lags) + ['V1']

ss=[None]
for e in eyes:
    for n in lags:
        for channel in xrange(2,sf_channels+1):
            for l in center_polarities:
                ss += [e+'LGN'+l+n+'SF'+str(channel)]
    ss += [None]

lslist=[]
for opponent in opponent_types:
    ls=[None]
    for n in lags:
        for e in eyes:
            ls+=[e+opponent+'LGN'+l+n for l in center_polarities]+[None]
    lslist+=[ls]

es=[]
for e in eyes:
    for n in lags:
        for cone in cone_types:
            es += [e+cone+'Retina'+n]
        es += [None]

grid=[x for x in [vs]+lslist+[ss,es] if len(x)>0]
overall_width=(1.0+len(eyes)*len(center_polarities)*len(lags))
topo.sim.grid_layout(grid, xstep=75*5/overall_width, ystep=50, item_scale=1.5/overall_width+0.1)

### Vertical grouping of sheets for GUI
for e in eyes:
    for n in lags:
        for cone in cone_types:
            topo.sim[e+cone+'Retina'+n].row_precedence=0.1
        for l,pol_precedence in zip(center_polarities,range(len(center_polarities))):
            for opponent in opponent_types:
                topo.sim[e+opponent+'LGN'+l+n].row_precedence=0.35+0.01*pol_precedence
            for channel in xrange(2,sf_channels+1):
                topo.sim[e+'LGN'+l+n+'SF'+str(channel)].row_predecence=0.35+0.01*pol_precedence
topo.sim['V1'].row_precedence=0.9


### Set up appropriate defaults for analysis
import topo.command

# Declare which maps to measure
# CEBALERT: get 'Hue Preference' twice for 'cr' (because having 'rg'
# in dims causes 'cr' to be added also)
preference_maps=[
('dy',['PhaseDisparity Preference']),
('cr',['Hue Preference']),
('rg',['Hue Preference']),
('dr',['Direction Preference']),
('or',['Orientation Preference']),
('od',['Ocular Preference']),
('sf',['Spatial Frequency Preference']),
]
pgs = [x for y in [m for n,m in preference_maps if n in p.dims] for x in y] + \
      ['Position Preference','Activity']
topo.command.default_analysis_plotgroups=pgs


wide_relative_sizes=[0.5*sf_relative_sizes[0]] + sf_relative_sizes + [2.0*sf_relative_sizes[-1]]
relative_sizes=(wide_relative_sizes if p.expand_sf_test_range else sf_relative_sizes)


# Set up defaults for measure_sine_pref, which is used for or, od, and sf
from topo.analysis.featureresponses import SinusoidalMeasureResponseCommand
if 'sf' in p.dims: SinusoidalMeasureResponseCommand.frequencies = [2.4*s for s in relative_sizes]
from topo.command.analysis import measure_sine_pref
if 'od' in p.dims: measure_sine_pref.num_ocularity=2
# Including the rest in measure_sine_pref is usually not computationally feasible:
#if 'dr' in p.dims: measure_sine_pref.num_direction=6
#if 'dr' in p.dims: measure_sine_pref.num_speeds=4
#if 'rg' in p.dims: measure_sine_pref.num_hue=8
#if 'cr' in p.dims: measure_sine_pref.num_hue=8
#if 'dy' in p.dims: measure_sine_pref.num_disparity=6 # 12


# Measure feature maps based on unthresholded initial response for
# speed and reliability
from topo.analysis.featureresponses import MeasureResponseCommand
MeasureResponseCommand.duration=0.175
MeasureResponseCommand.apply_output_fns=False


# CB: I guess we should actually have the specification for these back
# in topo.command.analysis...but not create the objects there. We
# already do that elsewhere with plotgrouptemplates for
# templateplotgroups, right?
from topo.command.pylabplot import overlaid_plots
combined_preference_maps = {
    ('or','od'):dict(
        name='Orientation and Ocular Preference',
        doc='Plot the orientation preference overlaid with ocular dominance boundaries.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference"},{"Strength":"OrientationSelectivity"}],overlay=[("contours","OcularPreference",0.5,"black")])],
        normalize='None'),

    ('or','dr'):dict(
        name='Orientation and Direction Preference',
        doc='Plot the orientation preference overlaid with direction preference arrows.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference"}],overlay=[("arrows","DirectionPreference","DirectionSelectivity","white")])],
        normalize='None'),

    ('or','dy'):dict(
        name='Orientation and PhaseDisparity Preference',
        doc='Plot the orientation preference overlaid with phase disparity preference boundaries.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference","Confidence":"OrientationSelectivity"},{"Strength":"OrientationSelectivity"}],overlay=[("contours","PhasedisparityPreference",0.83,"magenta"),("contours","PhasedisparityPreference",0.08,"yellow")])],
        normalize='None'),

    ('or','cr'):dict(
        name='Orientation and Hue Preference',
        doc='Plot the orientation preference overlaid with hue preference boundaries.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference","Confidence":"OrientationSelectivity"},{"Strength":"OrientationSelectivity"}],overlay=[("contours","HuePreference",0.9,"red"),("contours","HuePreference",0.4,"green")],normalize=True)],
        normalize='Individually'),

    ('or','od','dr'):dict(
        name='Orientation, Ocular and Direction Preference',
        doc='Plot the orientation preference overlaid with ocular dominance boundaries and direction preference arrows.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OrientationPreference"},{"Strength":"OrientationSelectivity"}],overlay=[("contours","OcularPreference",0.5,"black"),("arrows","DirectionPreference","DirectionSelectivity","white")])],
        normalize='None'),

    ('od','cr'):dict(
        name='Ocular and Hue Preference',
        doc='Plot the ocular preference overlaid with hue preference boundaries.',
        pre_plot_hooks=[],
        plot_hooks=[overlaid_plots.instance(plot_template=[{"Hue":"OcularPreference","Confidence":"OcularSelectivity"},{"Strength":"OcularSelectivity"}],overlay=[("contours","HuePreference",0.9,"red"),("contours","HuePreference",0.4,"green")],normalize=True)],
        normalize='Individually')
    }


## Create appropriate combined plots
from topo.plotting.plotgroup import create_plotgroup
for combined_dimensions,plotgroup_spec in combined_preference_maps.items():
    plotgroup_spec['category']="Combined Preference Maps"
    if set(p.dims).issuperset(set(combined_dimensions)):
        create_plotgroup(**plotgroup_spec)

# CB: could this be in create_plotgroup?
if hasattr(topo,'guimain'):
    topo.guimain.refresh_plots_menu()
